---
{"dg-publish":true,"permalink":"/czc知识库/1-计算机/机器学习相关 坤器学习/机器学习笔记/","dgPassFrontmatter":true,"created":"2024-06-18T17:45:21.186+08:00","updated":"2024-12-08T12:27:09.812+08:00"}
---


一包名词：
DNN：Deep neural network，深度神经网络
CNN：Convolutional neural network，[[czc知识库/1-计算机/机器学习相关 坤器学习/卷积神经网络\|卷积神经网络]]
RNN：Recurrent Neural Network，循环神经网络
DBN：Deep belief network，深度信念网络
LSTM：Long short-term memory，长短期记忆网络

GNN：[[czc知识库/1-计算机/机器学习相关 坤器学习/图神经网络\|图神经网络]]
GCN：Graph Convolutional Network，图卷积神经网络
GAT：Graph Attention Networks，[[czc知识库/1-计算机/机器学习相关 坤器学习/图注意力网络\|图注意力网络]]

PTM：Pre-train Model[预训练模型是什么](预训练模型是什么.md))
BART：**B**idirectional and **A**uto-**R**egressive **T**ransformers，双向自回归transformer？
权重矩阵[权重矩阵](权重矩阵.md))




---
---
---
以下笔记基本来自于智能计算系统课程
# 机器学习
人工智能先驱阿瑟·塞缪尔 (Arthur Samuel) 将机器学习描述为一组方法和技术，“赋予计算机无需明确编程的学习能力”。

---
安装miniconda
sh Miniconda3-py39_4.12.0-Linux-x86_64.sh -b
安装深度学习框架和d2l软件包

---

# 1 引言

机器学习中的关键组件：可以用来学习的**数据**；如何转换数据的**模型**；一个**目标函数**，用来量化模型的有效性；调整模型参数以优化目标函数的**优化算法**(algorithm)

## 1-3 各种机器学习问题

### 1-3-1 监督学习

监督学习的学习过程：获取训练数据集；选择有监督的学习算法，输入训练数据集，输出已完成学习的模型；使用模型预测之前没有见过的样本特征的标签

回归（regression）：“**训练一个回归函数来输出一个数值**” (“动手学深度学习.pdf”, p. 41)。根据特征向量预测标签数值。最简单的监督学习任务之一。 (“动手学深度学习.pdf”, p. 41)

分类（classification）：“**训练一个分类器来 输出预测的类别**” (“动手学深度学习.pdf”, p. 41)

标记问题

搜索

推荐系统

序列学习

标记和解析（寻找英文句子中的实体）、自动语音识别、文本转语言、机器翻译

### 1-3-2 无监督学习（unsupervised learning）

聚类（clustering）：

主成分分析（principal component analysis）：

因果关系（causality）和概率图模型（probabilisitic graphical models）问题：

生成对抗性网络（generative adversarial networks）：
![](/img/user/czc知识库/9-无奇不有/9-附件/附件/机器学习笔记_image.png) 
(“动手学深度学习.pdf”, p. 48)

## 1-3-4 强化学习
![](/img/user/czc知识库/9-无奇不有/9-附件/附件/机器学习笔记_image-1.png)  
(“动手学深度学习.pdf”, p. 49)

在强化学习问题中，智能体（agent）在一系列的时间步骤上与环境交互。在每个特定时间点，智能体从环境 接收一些观察（observation），并且必须选择一个动作（action），然后通过某种机制（有时称为执行器）将 其传输回环境，最后智能体从环境中获得奖励（reward）。此后新一轮循环开始，智能体接收后续观察，并 选择后续操作，依此类推。

强化学习框架的通用性十分强大。例如，我们可以将任何监督学习问题转化为强化学习问题

---

# 2 预备知识

R → R

2-1-2 运算符

张量连结在一起时按照轴来连接

0轴：第一维：行，添加在矩阵的下面

1轴：第二维：列，添加在矩阵的右边

2轴：第三维：高向？✔√

### 神经网络

### 卷积神经网络（CNN）：

CNN是一类专门用于处理网格化数据，尤其是图像和视频的深度学习模型。它是由卷积层和池化层构成的深层神经网络。CNN 在计算机视觉任务中有很大的优势和应用，如图像分类、目标检测和图像生成等。（之前高级算法设计与分析的大作业就是用采用CNN的yolo模型来进行目标检测）

卷积神经网络的主要组成部分：
1.**卷积层：** 卷积操作是 CNN 的核心。通过卷积操作，网络能够检测输入数据中的局部特征。卷积层使用卷积核（filter）对输入图像进行滑动运算，提取局部特征。这有助于网络捕捉图像的空间层级结构。
2.**激活函数：** 激活函数引入非线性性质，使得网络可以学习更加复杂的映射关系。常用的激活函数包括ReLU（Rectified Linear Unit）、Sigmoid和Tanh。
3.**池化层：** 池化操作有助于降低数据维度，并保留最重要的信息。最大池化是一种常见的操作，它在每个区域选择最大值作为池化后的值。
4.**全连接层：** 在卷积神经网络的尾部，通常会添加全连接层，将卷积层提取的特征映射转换为最终的输出。这些层通常用于进行分类或回归等任务。
5.**归一化：** 批量归一化被广泛用于卷积神经网络，有助于加速训练过程，提高模型的鲁棒性。

  卷积神经网络的优势在于它能够利用权值共享和局部感受野的设计，减少参数数量，提高对平移不变性的学习能力。这使得 CNN 在处理图像等网格化数据时表现出色，广泛应用于图像处理、计算机视觉和深度学习任务。

### 循环神经网络：

有一个自反馈的机制，具有记忆功能

RNN是一类专门用于处理序列数据的神经网络，它具有记忆功能，能够在处理序列时考虑之前的信息。与传统的前馈神经网络不同，RNN 具有反馈连接，允许信息在网络中传递。

### 生成对抗网络

GAN 的特点在于它包含两个相互竞争的神经网络：生成器（伪装者）和判别器（警察）。

1.生成器的目标是生成与真实数据相似的新数据。尽可能生成能以假乱真的样本，使判别网络输出接近0.5（难以区分真假）。一旦被判别器发现假，生成器就会调整自己的参数使输出更真实

2.判别器的任务是区分生成器生成的数据和真实训练数据。判断输入数据是来自真是样本集还是生成样本集，如真输出1，如假输出0。生成器成功骗过判别器，则跳转判别器参数使检测能力更强。

3.**对抗训练：** GAN 的训练过程是一个对抗的过程。生成器和判别器相互竞争，通过不断优化它们的参数，使得生成器生成的数据越来越逼真，而判别器更难区分生成的数据和真实数据。




# 联邦学习（Federated Learning）
#机器学习/联邦学习![联邦学习](联邦学习.md))

# 名词解释：![概念漂移](概念漂移.md))
![权重矩阵](权重矩阵.md))


## 什么是梯度、梯度下降、求导和其是什么关系
上智能计算系统课<font color="#ff0000">听不懂系列</font>，为什么不上万能的b站大学呢？？？
[深度学习 与 梯度 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/668156356)

方向导数是**导数**，梯度是在某点使得函数值增加最快的**方向**
在一元函数中：**梯度** 表示的自变量 x 移动的 **方向**, 可以通过 **导数** 的方式求解! 两者是两个概念!
## （激活函数，损失函数，反向传播怎么实现，什么是计算图机构）

## 控制流？
