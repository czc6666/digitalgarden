---
{"dg-publish":true,"permalink":"/czc知识库/计算机/机器学习相关 坤器学习/网格搜索是什么--超参数优化方法 机器学习/","dgPassFrontmatter":true,"created":"2024-06-18T17:45:20.774+08:00","updated":"2024-12-08T12:25:39.582+08:00"}
---


看代码的时候遇到的，学一下


具体代码：
```python
# 定义超参数网格，用于模型的网格搜索  
param_grid = {'penalty': ['l2'],  
	'loss': ['hinge', 'squared_hinge'],  
	'tol': [0.0001, 0.00025, 0.0005, 0.001, 0.003],  
	'C': [0.01, 0.26, 0.51, 0.76, 1],  
	'max_iter': list(range(1000, 12000, 2500))}  
  
kappa_scorer = cohen_kappa_score # 定义评估指标  
  
svm = LinearSVC  
  
# 网格搜索 (GridSearchCV) 寻找最佳超参数  
best = self._GridSearchCV(X, Y, svm, param_grid, kf_cv=kf, scorer=kappa_scorer)  
self._best_params = best[0] # 保存最佳模型参数 best_paramsprint('Selected', self._best_params, 'with CV score', best[1])  
  
X, Y = self._computeFeatureSet(X, Y) # 调用 _computeFeatureSet 方法计算特征集。  
  
self._clf = LinearSVC(**self._best_params) # 初始化线性支持向量机分类器 (LinearSVC)，  
self._clf.fit(X, Y) # 并用最佳参数 best_params 进行训练。  
y_pred = self._clf.predict(X) # 对训练集进行预测，并计算模型在训练集上的评估指标
```
> [!NOTE] ChatGPT解释：
> 网格搜索（Grid Search）是一种超参数优化的方法，用于在给定的超参数范围内系统地搜索最优的超参数组合。在机器学习中，超参数是模型在训练之前需要设定的参数，它们不能通过模型训练过程中的优化算法进行学习，而是需要手动指定。
> 
> 网格搜索的基本思想是定义一个超参数的网格（即参数空间），将所有可能的超参数组合列出，并对每一组超参数进行模型训练和评估，最终选择表现最好的超参数组合作为最佳模型配置。
> 
> 具体步骤如下：
> 
> 1. **定义参数空间：** 对需要调节的超参数设定取值范围或候选值。
>     
> 2. **构建参数网格：** 将各个超参数的候选值组合成一个网格，形成所有可能的超参数组合。
>     
> 3. **模型训练和评估：** 对于每个超参数组合，使用交叉验证等方法对模型进行训练和评估，得到模型在验证集上的性能指标。
>     
> 4. **选择最佳超参数组合：** 根据性能指标（如准确率、F1 分数、AUC 等）选择表现最好的超参数组合作为最终的模型配置。
>     
> 
> 网格搜索的优点是简单直观，能够遍历所有可能的超参数组合，找到最优配置。然而，由于需要遍历大量的参数组合，计算成本较高，尤其是在参数空间较大时。因此，在实际应用中，通常会结合其他方法（如随机搜索、贝叶斯优化等）来进行超参数优化，以提高效率和性能。


