---
{"dg-publish":true,"permalink":"/czc知识库/计算机/机器学习相关 坤器学习/胶囊网络是什么：更强的可解释性/","dgPassFrontmatter":true,"created":"2024-06-18T17:45:20.784+08:00","updated":"2024-12-08T12:25:39.587+08:00"}
---


# 胶囊网络：更强的可解释性 - 知乎
[胶囊网络：更强的可解释性 - 知乎](https://zhuanlan.zhihu.com/p/264910554)
## 胶囊网络（Capsule Network）

胶囊网络是Hinton老头子前两年提出来的，认为未来可以替换传统神经网络的一种新的神经网络。胶囊的设计更符合人类神经元的原理。

目前胶囊网络还没有实际的应用，但是学习胶囊网络可以帮助我们更深刻的理解神经网络的原理和其在可解释性方面的缺陷。

简单来说，将神经元替换为胶囊，就是胶囊网络。

# 万字胶囊网络超详细总结（原理加pytorch代码（要钱））
[# 万字胶囊网络超详细总结（原理加pytorch代码（要钱））](https://blog.csdn.net/m0_46384757/article/details/121559514)


# 胶囊网络为什么不流行？ - 知乎
[(4 封私信 / 51 条消息) 胶囊网络为什么不流行？ - 知乎](https://www.zhihu.com/question/533501088)

[胶囊网络](https://www.zhihu.com/search?q=%E8%83%B6%E5%9B%8A%E7%BD%91%E7%BB%9C&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3072437339%7D)（Capsule Network）经时间的检验逐渐消失在历史长河中，因为其复杂的训练过程、较大的计算开销和 大。但是，胶囊网络具有以下优点：

1. [鲁棒性](https://www.zhihu.com/search?q=%E9%B2%81%E6%A3%92%E6%80%A7&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3072437339%7D)：通过[动态路由](https://www.zhihu.com/search?q=%E5%8A%A8%E6%80%81%E8%B7%AF%E7%94%B1&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3072437339%7D)算法，胶囊网络能够增强相关特征之间的权重，减弱无关特征之间的权重；
2. 关系建模：通过胶囊之间的动态路由和权重计算，胶囊网络能够推断实体之间的关联程度和空间排列，进而实现更高级的推理和推断能力。
3. 可解释性：由于胶囊网络中的胶囊具有明确的语义含义，且胶囊网络的输出可以被解释为对不同实体或特征的激活程度，从而使得模型的预测结果更具可解释性。

那么，有什么算法拥有上述优点并且训练过程简单和计算开销小呢？SENet作为一种[通道注意力机制](https://www.zhihu.com/search?q=%E9%80%9A%E9%81%93%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3072437339%7D)可以很好地代替胶囊网络在实际中的应用。

胶囊网络的核心：每个胶囊层中的胶囊由一个向量表示，记为 𝑢𝑖，其中 𝑖∈[0,𝑚) ， 𝑚 为胶囊个数。胶囊层的输出向量 𝑣_可以通过对上一层胶囊的输出_ 𝑢𝑖进行加权求和得到。权重由动态路由算法确定，步骤如下：

- a) [初始化权重系数](https://www.zhihu.com/search?q=%E5%88%9D%E5%A7%8B%E5%8C%96%E6%9D%83%E9%87%8D%E7%B3%BB%E6%95%B0&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3072437339%7D)𝑏𝑖 为零。
- b) [迭代轮次](https://www.zhihu.com/search?q=%E8%BF%AD%E4%BB%A3%E8%BD%AE%E6%AC%A1&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3072437339%7D)𝑟 ，进行以下计算：
- 通过胶囊输入 𝑢𝑖 乘以权重系数 𝑐𝑖=𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑏)[加权求和](https://www.zhihu.com/search?q=%E5%8A%A0%E6%9D%83%E6%B1%82%E5%92%8C&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3072437339%7D)： 𝑣=∑𝑖𝑐𝑖𝑢𝑖 。
- 使用[非线性激活函数](https://www.zhihu.com/search?q=%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3072437339%7D)𝑠=Squash(𝑣) 对输出向量进行[归一化](https://www.zhihu.com/search?q=%E5%BD%92%E4%B8%80%E5%8C%96&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3072437339%7D)，其中 Squash(⋅) 是胶囊网络中常用的归一化函数。
- 根据输出 𝑠 和下一层胶囊的输出 𝑢𝑖 的[内积](https://www.zhihu.com/search?q=%E5%86%85%E7%A7%AF&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3072437339%7D)： 𝑏𝑖=𝑏𝑖+𝑠⋅𝑢𝑖 。
- c) 最后，通过[迭代计算](https://www.zhihu.com/search?q=%E8%BF%AD%E4%BB%A3%E8%AE%A1%E7%AE%97&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3072437339%7D)得到的权重系数 𝑏 对下一层胶囊的输出 𝑢𝑖 进行加权求和： 𝑣=∑𝑖𝑏𝑖𝑢𝑖 。

总结胶囊网络：根据 𝑚 个胶囊𝑢𝑖加权求和输出胶囊 𝑣 ，权重类似于[k-means](https://www.zhihu.com/search?q=k-means&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3072437339%7D)算法由迭代产生。因此，胶囊网络也可以看成一个聚类过程，将多个向量（胶囊）聚类为一个向量（胶囊）。

自然而然地，我们可以用SENet代替胶囊网络。SENet将多个[通道向量](https://www.zhihu.com/search?q=%E9%80%9A%E9%81%93%E5%90%91%E9%87%8F&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3072437339%7D)压缩成一个向量。

SENet公式为： 𝑣=sigmoid(𝑊2⋅ReLU(𝑊1⋅𝑈)) ，其中[全连接层](https://www.zhihu.com/search?q=%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3072437339%7D)的参数为 𝑊1∈𝑅𝐶×𝑚 和 𝑊2∈𝑅1×𝐶 。 𝑊2 类似于胶囊网络中的权重，进而使得SENet具备了胶囊网络的优点。进一步了解SENet，可看[懒羊羊学AI：深入理解SENet：自适应特征提取的注意力机制](https://zhuanlan.zhihu.com/p/630036643)。